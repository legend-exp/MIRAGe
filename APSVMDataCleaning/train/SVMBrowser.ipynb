{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Browser\n",
    "\n",
    "This notebook takes in a sample of normalized discrete wavelete transform approximation coefficients with corresponding data cleaning labels and outputs a trained SVM model. First, we load modules and files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load modules\n",
    "import time, pickle, json, lgdo\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "# Load files\n",
    "dsp_file = '../data/l200-*-ml_train_dsp.lh5'\n",
    "sto = lgdo.lh5.LH5Store()\n",
    "tb_dsp, _ = sto.read('ml_train/dsp', dsp_file)\n",
    "\n",
    "with open('../data/hyperparameters.json', 'r') as infile:\n",
    "    hyperparams_dict = json.load(infile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define the training inputs that will go into the SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dwts_norm = tb_dsp['dwt_norm'].nda\n",
    "labels = tb_dsp['dc_label'].nda\n",
    "SVM_hyperparams = hyperparams_dict['SVM']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we train the SVM with the optimal hyperparameters found, and then save the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 3.4810590744018555 seconds ---\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(random_state=SVM_hyperparams['random_state'], \n",
    "          kernel=SVM_hyperparams['kernel'], \n",
    "          decision_function_shape=SVM_hyperparams['decision_function_shape'],\n",
    "          class_weight=SVM_hyperparams['class_weight'],\n",
    "          C=float(SVM_hyperparams['C']),\n",
    "          gamma=float(SVM_hyperparams['gamma']))\n",
    "\n",
    "start_time = time.time()\n",
    "svm.fit(dwts_norm, labels)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "with open(\"../data/svm.pkl\", \"wb\") as svm_file:\n",
    "    pickle.dump(svm, svm_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we save the trained model hyperparameters to be read by Julia as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 2969268.55357526,\n",
       " 'break_ties': False,\n",
       " 'cache_size': 200,\n",
       " 'class_weight': 'balanced',\n",
       " 'coef0': 0.0,\n",
       " 'decision_function_shape': 'ovr',\n",
       " 'degree': 3,\n",
       " 'gamma': 0.06509150378608647,\n",
       " 'kernel': 'rbf',\n",
       " 'max_iter': -1,\n",
       " 'probability': False,\n",
       " 'random_state': 0,\n",
       " 'shrinking': True,\n",
       " 'tol': 0.001,\n",
       " 'verbose': False}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_pars = svm.get_params()\n",
    "svm_pars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classes = svm.classes_\n",
    "weights = svm.class_weight_\n",
    "\n",
    "weights_dict = {}\n",
    "for cl, wt in zip(classes, weights):\n",
    "    weights_dict[cl] = wt\n",
    "    \n",
    "julia_svm_pars = {\n",
    "    \"degree\" : svm_pars[\"degree\"],\n",
    "    \"gamma\" : svm_pars[\"gamma\"],\n",
    "    \"cache_size\" : svm_pars[\"cache_size\"],\n",
    "    \"coef0\" : svm_pars[\"coef0\"],\n",
    "    \"cost\" : svm_pars[\"C\"],\n",
    "    \"tolerance\" : svm_pars[\"tol\"],\n",
    "    \"shrinking\" : svm_pars[\"shrinking\"],\n",
    "    \"probability\" : svm_pars[\"probability\"],\n",
    "    \"weights\" : weights_dict,\n",
    "    \"verbose\" : svm_pars[\"verbose\"]\n",
    "}\n",
    "julia_svm_pars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('../data/hyperparameters_julia.json', 'w') as f:\n",
    "    json.dump(julia_svm_pars, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/hyperparameters_pygama.json', 'w') as pf:\n",
    "    json.dump(svm_pars, pf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "legend-software",
   "language": "python",
   "name": "legend-software"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
